{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    " Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is 0\n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|                                  | **Unsatisfactory**                                                                                                                                                                                                                                                                                                                        | **Developing**                                                                                                                                                                                                       | **Proficient**                                                                                                                                                                                            | **Excellent**                                                                                                                                                                            |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **EDA relevance**                | EDA is mostly neither relevant to the question nor helpful in figuring out how to address the question. Or the EDA does address the question, but many obviously relevant variables / analyses / figures were not included. | EDA is partly irrelevant/unhelpful. EDA missed one or two obvioulsy relevant analysis (distributions of single variables or relationships between variables) | EDA includes the obviously relevant / helpful variables in addressing the question.                                                              | Thorough EDA fully explored the dataset                                                                                                                 |\n",
    "| **EDA analysis and description** | Many of the analyses are poor choices (e.g., using means instead of medians for obviously skewed data), or are poorly described in the text, or do not aid understanding the data                                                                                                                                                     | Some of the analyses are poor choices, or are poorly described in the text, or do not aid understanding the data                                                                                                 | All analyses are correct choices. Only one or two have minor issues in the text descriptions supporting them. Mostly they fit well with other elements of the EDA and support understanding the data  | All analyses are correct choices with clear text descriptions supporting them. The figures fit well with the other elements of the EDA, producing a clear understanding of the data. |\n",
    "| **EDA figures**                  | Many of the figures are poor plot choices (e.g., using a bar plot to represent a time series where it would be better to use a line plot) or have poor aesthetics (including colormap, data point shape/color, axis labels, titles, annotations, text legibility) or do not aid understanding the data                                | Some of the figures are poor plot choices or have poor aesthetics. Some figures do not aid understanding the data                                                                                                | All figures are correct plot choices. Only one or two have minor questionable aesthetic choices. The figures mostly fit well with the other elements of the EDA and support understanding the data    | All figures are correct plot choices with beautiful aesthetics. The figures fit well with the other elements of the EDA, producing a clear understanding of the data.                |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Aaron Chakma: \n",
    "Amara Ihekwoeme: \n",
    "Marco Krause: \n",
    "Dustin Miller: \n",
    "Kera Yu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In New York City, how does taxi and ride hailing activity (Uber and Lyft proxy via TLC HVFHV trips) affect the nearest MTA subway station ridership (total riders per day) on a daily level from March to November 2025, controlling for trends such as seasonality, weather, and gas prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Public transit agencies have pursued service expansions and frequency improvements to attract riders, yet many U.S. cities experienced stagnation or decline in ridership in the years leading up to COVID-19. A Congressional Research Service review notes that despite major capital investments (including rail expansions), overall ridership fell in many large markets, and new rail lines do not necessarily increase total system ridership– sometimes shifting resources away from bus networks that carry a large share of trips.<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup> At the same time, multiple competitive and behavioral forces changed the travel market: cheaper gasoline, rising fares, telework, and the growth of alternative modes like bikeshare and ride-hailing.<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup>\n",
    "\n",
    "## Prior work\n",
    "Recent empirical work suggests that transit supply improvements can raise ridership, but the net outcome depends on the broader context. Erhardt et al. (2022) quantify ridership change across U.S. metropolitan areas pre-pandemic and find that while expanded transit service and land-use changes would have increased ridership, these gains were outweighed by other factors—especially ride-hailing along with higher fares, higher incomes, more teleworking, higher car ownership, and lower gas prices.<sup><a href=\"#fn3\" id=\"ref3\">3</a></sup> Complementing this, Graehler et al. (TRB 2019) document mode-specific ridership declines in major U.S. cities since the mid-2010s and enumerate commonly cited explanations including service cuts, deferred-maintenance reliability issues, micro mobility growth, and Transportation Network Company(TNC) expansion(Uber/Lyft); their panel analysis finds that standard factors (service levels, gas price, auto ownership) do not fully explain the recent declines and reports negative associations between years-since-TNC entry and bus/heavy-rail ridership.<sup><a href=\"#fn2\" id=\"ref2\">2</a></sup>\n",
    "\n",
    "## Motivation for this project\n",
    "New York City subway system is a critical part of its transportation with millions of people ridiing it daily. The increase in use of uber and lyft, with over half a million uber and lyft rides requested in New York City alone, people raise the question of whether these services pulling away riders from the subway system. It's a well known fact that public transport systems, such as MTA, generally lose money by being in operations. With ride hailing becoming a increasing way that people transport through the city, it may increase that defecit. To further investigate Erhardt et al. and Graehler et al. research claims, with our analysis we would be able to really pinpoint where the ridership declines and ridehailing increases. \n",
    "\n",
    "\n",
    "## References (Footnotes)\n",
    "\n",
    "<p id=\"fn1\">\n",
    "1. Mallett, W. J. (2018). <i>Trends in Public Transportation Ridership: Implications for Federal Policy</i> (CRS Report R45144). Congressional Research Service.\n",
    "<a href=\"https://www.congress.gov/crs_external_products/R/PDF/R45144/R45144.3.pdf\">https://www.congress.gov/crs_external_products/R/PDF/R45144/R45144.3.pdf</a>\n",
    "<a href=\"#ref1\">^</a>\n",
    "</p>\n",
    "\n",
    "<p id=\"fn2\">\n",
    "2. Erhardt, G. D., et al. (2022). Why has public transit ridership declined in the United States?\n",
    "<i>Transportation Research Part A</i>, 161, 68–87.\n",
    "<a href=\"https://www.sciencedirect.com/science/article/pii/S0965856422000945\">https://www.sciencedirect.com/science/article/pii/S0965856422000945</a>\n",
    "<a href=\"#ref2\">^</a>\n",
    "</p>\n",
    "\n",
    "<p id=\"fn3\">\n",
    "3. Tabassum, N., et al. (2025). Ways of increasing transit ridership—lessons learned from successful transit agencies.\n",
    "<i>Case Studies on Transport Policy</i>, 19.\n",
    "<a href=\"https://www.sciencedirect.com/science/article/pii/S2213624X24002177\">https://www.sciencedirect.com/science/article/pii/S2213624X24002177</a>\n",
    "<a href=\"#ref3\">^</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After accounting for trends (seasonality, weather, and gas prices), stations with high surrounding ride hailing activity will have a lower number of riders per day. We anticipate that during more intense weather conditions (heat, cold, rain, and snow), subway stations will experience less ridership and ride hailing activity will increase accordingly. Furthermore, we anticipate as gas prices increase, ridesharing prices will follow suit, lowering their ridership, and increasing subway ridership.\n",
    "\n",
    "The hypothesized thresholds are as follows:\n",
    "\n",
    "- Temperature (on days when it is not raining or snowing): \n",
    "    - Lower threshold: 50°F (10°C) (temperatures below this will lead to a decrease in subway ridership)\n",
    "    - Upper threshold: 80°F (27°C) (temperatures above this will lead to a decrease in subway ridership)\n",
    "- Rain: rain for over 1/3 of the day will see a decrease in ridership\n",
    "- Snow: any amount of snow will lead to a decrease in ridership\n",
    "- Gas Prices: $3.50 (gas prices exceeding this amount will lead to increased subway ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "### MTA Subway Hourly Ridership: Beginning 2025\n",
    "- Dataset Name: MTA Subway Hourly Ridership: Beginning 2025\n",
    "- Link to the dataset: https://data.ny.gov/Transportation/MTA-Subway-Hourly-Ridership-Beginning-2025/5wq4-mkjj/about_data \n",
    "- Number of observations: 32.6 Million\n",
    "- Number of variables: 12\n",
    "- Description of the variables most relevant to this project\n",
    "    - transit_timestamp - The date and time in which the payment took place, rounded to the nearest hour\n",
    "    - transit_mode - Distinguishes between the subway, Staten Island Railway, and the Roosevelt Island Tram. We will be using only the subway\n",
    "    - station_complex - The subway complex where an entry swipe or tap took place. Large subway complexes, such as Times Square and Fulton Center, may contain multiple subway lines. The subway complex name includes the routes that stop at the complex in parenthesis, such as Zerega Av (6).\n",
    "    - ridership - Total number of riders that entered a subway complex via OMNY or MetroCard at the specific hour and for that specific fare type.\n",
    "    - latitude - Latitude for the specified subway complex\n",
    "    - longitude - Longitude for the specified subway complex\n",
    "- Descriptions of any shortcomings this dataset has with respect to the project\n",
    "    - The dataset is massive and will take some clever querying and processing to make it manageable.\n",
    "    - The dataset begins in March 2025, so we will have to match the rest of the datasets we use to this constraint.\n",
    "\n",
    "### Ride Hailing Dataset \n",
    "- Dataset Name: High Value For Hire Vehicle Data\n",
    "- Link to the dataset: ([https://data.cityofnewyork.us/Transportation/2023-High-Volume-FHV-Trip-Data/u253-aew4/about_data])\n",
    "- Number of observations: 707211 \n",
    "- Number of variables: 14\n",
    "- The variables most relevant are pickup date/time, Pickup Location, and the total cost.\n",
    "- Descriptions of any shortcomings this dataset has with respect to the project\n",
    "- This dataset's biggest shortcomings is it's overachieving. It's quite literally every ride in New York on this day, so we need to compress the data greatly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- Run only once after cloning!!! \n",
    "#\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTA Subway Hourly Ridership\n",
    "\n",
    "The main variable that we are interested in is ridership, which is the total number of riders that entered a subway recorded through the New York City payment system card. This ridership value includes transfers, those who use a free bus-to-subway or free out-of-network transportation. For example, Time Square station complexes could get thousands of entries while outskirts complexes could get significantly less. The MTA Subway Hourly Ridership would allow us to see the times of peak ridership along with the lows of ridership.\n",
    "\n",
    "A crucial variable that this dataset provides is transit_timestamps that are recorded to each hour, so a 1:37pm tie would be recorded as a 1:00pm transite_timestamp. The format is YYYY-MM-DDTHH:MM:SS.SSS, however the “:MM:SS.SSS” is always :00:00.000. As these are strings, this format allows us to use pd.to_datetime(), a more usable form.\n",
    "The location provided in the dataset is critical when analyzing other factors in comparison. Station_complex_id are the unique identifiers for station complexes while station_complex are the more human recognizable names of stations and these stations can support many subway lines. Another location specifying variable is latitude,  longitude, and borough which also be critical for when compared to other factors.\n",
    "\n",
    "\n",
    "One of the biggest concerns we have is the massive size of the datasets that we will be handling. Just the data from the beginning of 2025, there are more than 30,000 pages which each have 50 records. This would call for Parquet exports or loads of CSV files. They also limit the number of rows that can be pulled in a single request without a special access key. So we would need to make a multiple request or apply for the access key. \n",
    "\t\n",
    "Another concern is with ridership counts. Due to the ridership counts being counted based on fare payment transactions, those who evade subway fare will not be counted. So systemically, the ridership number will be underreported. MTA reports that subway fare evasion is around 10% which has decreased from the year before (https://cbcny.org/research/no-fare). Due to the volatile rate of fare evasion, it may bias the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ride Hailing Dataset\n",
    "Our dataset is provided by the NYC government, so it's publicly accessible, and contains transport data from janurary 1st 2023 to janurary 1st 2024 for high volume for hire vehicles. This includes services like Uber and Lyft. We chose this dataset because it aggregates all rideshare companies, and since their inception it takes up about 80% of the marketshate for ride-hailing services.\n",
    "\n",
    "The dataset has lots of metrics, but the ones that we are going to apply to our project are the pickup date and time, the location ID (Taxi Zones), the distance traveled, the trip time, and alot of the cost components like sales tax, base price, and additional fees. To clean the data, we aggregated the costs and combined the columns into a single total cost column. Our immediate goals don't nececitate these metrics, but we might use them for more analysis later on, so we placed it in the 01-interim folder temporarily. The dataset that we were provided was nearly perfect, and we did our due diligence checking for any abnormal behavior, but we concluded that it was fine as is, just needed to remove some columns.\n",
    "\n",
    "Note that due to the rather large datasize, we were unable to upload it via the URL, so we manually uploaded the 80MB file ourselves. The cleaned interim data is about 30MB, but this is just for one day. To concatenate the data, I created a function that can aggregate the entries into rides per hour per each taxi zone. This now matches the hourly format of the MTA data, and is much more processable at 172KB. Converting each day to this format will prove challenging due to the limitiations of the API, and the aformentioned large file sizes, but not impossible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "Instructions: replace the words in this subsection with whatever words you need to setup and preview the EDA you're going to do.   \n",
    "\n",
    "Please explicitly load the fully wrangled data you will use from `data/02-processed`.  This is a good idea rather than forcing people to re-run the data getting / wrangling cells above.  Sometimes it takes a long time to get / wrangle data compared to reloading the fixed up dataset.\n",
    "\n",
    "Carry out whatever EDA you need to for your project in the code cells below.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context.\n",
    "\n",
    "Please note that you should consider the use of python modules in your work.  Any code which gets called repeatedly should be modularized. So if you run the same pre-processing, analysis or visualiazation on different subsets of the data, then you should turn that into a function or class.  Put that function or class in a .py file that lives in `modules/`.  Import the module you made and use it to get your work done.  For reference see `get_raw()` which is inside `modules/get_data.py`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 of EDA - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 of EDA if you need it  - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> The datasets we are planning to use are directly from the public transit agencies. Due to the data being transit operations rather than individual user behavior, the traditional need for consent is not applicable. So I would say that the public transit riders may implicitly consent to data collection through the transit systems terms of use\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "> Collection biases that we may come across are those who evade transportation fares. They would not be counted in the ridership counts. However, I believe that this group would be negligible when compared to the overall ridership population. With this in mind, conclusions will always be estimations. Bias’s that would matter more is at what time the data is taken, COVID era would be an outlier due to the changes during that year. Along with bus ridership during school and when school is out would affect the ridership counts.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "> The data set that we are using does not have any personally identifying information. It consists of information such as aggregate ridership counts and schedule data.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "> The dataset does not include any demographic information such as race, gender, or socioeconomic status. Which would limit our ability to mitigate or even test for those factors, but also means that sensitive information is not at risk.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "> The data is from public agencies and public accessible and contains no personally identifiable information, there is no need for more security measures beyond ethically using the data.\n",
    "\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "> To reduce any blind spots, we are planning on drawing from multiple sources across agencies that do transportation in San Diego, which consist of San Diego County Metropolitan Transit System (SDMTS), North County Transit District (NCTD) and more. Using multiple sources will help validate findings and capture the bigger picture\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "> We know that there is a risk of our sources being biased which would make our data biased. Socioeconomic factors could influence ridership patterns, as a more transit-dependent community may respond differently to frequency changes than less dependent riders. If fare data is involved, we can normalize based on the area’s cost of living. Another factor to consider is the more heavily populated areas and high traffic places, may generate more ridership data. We will do our best to account for this by avoiding over generalizing any findings especially to those highly dense routes.\n",
    "\n",
    " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    ">Data with personal identifiable information was not collected, nor is it necessary for analysis, and thus will not be used or displayed.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    ">In the future, when generating the analysis, steps will be taken to ensure the process is well documented and reproducible. These steps will include keeping logs, frequent team communication, and transparency.\n",
    "\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    ">Data used is sourced from multiple references, which helps reduce the possibility of discrimination, both directly and through proxy. However, there is concern for bias by income or socioeconomic class when looking at fares and the rider population. \n",
    "\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    ">Yes, optimized metrics such as fare costs compared to cost of living does not have any apparent unintended effects. Additional metrics can include the local cost of gas, local parking prices, and/or drivability of surrounding areas.\n",
    "\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [ ] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    ">Our results are purely for informational purposes, not designed to be capable of harm. If harm through misrepresentation or misinterpretation were to arise, we can address the concerns on a case by case basis.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    ">Deletion or unpublication of our model can be easily done if necessary.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    ">As our model is purely informational, the primary risk for unintended uses or abuse comes from possible misinterpretations and/or misapplications of our results (such as using our data to justify slowing transportation in lower income neighborhoods). Once deployed, we can monitor the use and citations of our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Organization*\n",
    "    * Communication will be done over Discord and Imessage. Responses within 24 hours is appreciated, meetings will occur at least once a week either virtually or in person.\n",
    "* *Decision Making*\n",
    "    * A blunt but polite tone will be used within our team, members are expected to treat one another and their ideas with the same care and respect they wish to recieve.\n",
    "    * Decisions will be made by majority vote, though every member's concerns will be considered. Decisions made in constrained time frames or without the input of all team member will be followed up with at a later time, though unilateral decisions are discouraged.\n",
    "* *Contribution*\n",
    "    * Specializations will be sorted when more of the project is flushed out; these specializations will be fluid and dependant on what each member feels most comfortable doing.\n",
    "    * If a member of the group is struggling with something they promised to do, they must reach out to the group at the earliest possible time. Group effort reallocation will be decided on a case by case basis.\n",
    "* *Conflict*\n",
    "    * Communication is greatly encouraged, whether there is a problem with the project, the group, or individual members. This can be done through open conversations with an open mind on the group Discord or Imessage.\n",
    "    * If a problem with a teammate arises, open communication comes first, either one on one or as a group. If problems continue, the professor would be notified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/2  |  6 PM |  Do background research on potential topics and data sets. | Discuss ideal topic and hypothesis; draft project proposal. | \n",
    "| 2/4  |  6 PM | Work on allocated sections of project proposal. (Marco & Dustin: Background and Prior Work, Aaron: Data, Kera & Amara: Ethics)  | Edit, finalize, and submit Project Proposal. | \n",
    "| 2/11  | 7pm  | Think about possible improvements to project proposal. Find relevant primary and secondary datasets. | Team reflections on project proposal. Updates on found datasets, narrowing down data sets and scope of project.  |\n",
    "| 2/15  | 7pm  | Review project proposal feedback, continue investigation and refinement of data sets.  | Update project proposal according to TA and team feedback. Discuss data expectations and assign roles.  |\n",
    "| 2/16  | 7pm  | Start on individual responsibilities, both in data and project proposal updates. | Progress update on project proposal and data. Finalize updated project proposal. Inspect data structures, types, and potential issues.  |\n",
    "| 2/18  | 6pm  | Work on allocated sections of data checkpoint and roles. | Edit, finalize, and submit data checkpoint. Begin planning EDA and future steps.  |\n",
    "| 2/23  | 6pm  | Begin initial search for correlations; draft initial visualizations, identify potential trends/patterns, initial summary statistics. | Discuss findings, investigate outliers, evaluate initial models. Select model and relevant features to move forward with. Assign initial roles in model making.  |\n",
    "| 2/25  | 7pm  | Start on individual roles. Prepare necessary framework for models, tune parameters, set evaluation criteria. | Updates on model progresses. Redistribution of roles and responsibilities if needed.  |\n",
    "| 3/2  | 6pm  | Continue work on individual roles. Begin working on EDA checkpoint. | Compare performances of different models. Review and finalize model(s).   |\n",
    "| 3/4  | 6pm  | Experiment with different techniques and feature selections. Optimize best performing models. Other fine-tuning to reduce under/overfitting. Continue work on EDA checkpoint. | Assess final models on test set and performance metrics, compare results with baseline. Review, edit, and submit EDA checkpoint. Begin analysis and interpretation of model results, assign roles.  |\n",
    "| 3/9  | 7pm  | Continue assigned analysis and investigations. Note key findings, insights, patterns. Write initial conclusions. | Compare and compile conclusions and analyses. Discuss next steps; address concerns, limitations, or assumptions brought up from analysis.  |\n",
    "| 3/11  | 6pm  | Address last meeting’s concerns; fine tune model, edit analysis as needed. Begin filling in final project. | Discuss final project and video roles and responsibilities based off of work left over. Review, edit, finalize what was already done.  |\n",
    "| 3/16  | 7pm  | Work on individual roles. Identify any possible improvements. | Update on progress of final project and video. Address concerns, ensure project progress is as planned.  |\n",
    "| 3/18  | 6pm  | Finalize individual sections and responsibilities. | Review, edit, and finalize final project and video. Submit!  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
